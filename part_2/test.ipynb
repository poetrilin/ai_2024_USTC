{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 0.2311,    -inf,  0.5954],\n",
      "         [-0.0703,    -inf,  0.4617],\n",
      "         [   -inf, -0.4893, -0.9320],\n",
      "         [ 1.0221, -0.2265,    -inf]],\n",
      "\n",
      "        [[ 0.2978,    -inf,  2.8054],\n",
      "         [ 0.8387,    -inf,  0.4485],\n",
      "         [   -inf,  0.4890,  0.7525],\n",
      "         [-0.6014,    -inf,  0.3680]]])\n",
      "tensor([[[0.4099, 0.0000, 0.5901],\n",
      "         [0.3700, 0.0000, 0.6300],\n",
      "         [0.0000, 0.6089, 0.3911],\n",
      "         [0.7771, 0.2229, 0.0000]],\n",
      "\n",
      "        [[0.0753, 0.0000, 0.9247],\n",
      "         [0.5963, 0.0000, 0.4037],\n",
      "         [0.0000, 0.4345, 0.5655],\n",
      "         [0.2750, 0.0000, 0.7250]]])\n"
     ]
    }
   ],
   "source": [
    "# scores shape is [batch_size, seq_len,num_experts]\n",
    "import torch.nn.functional as F\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "num_experts = 3\n",
    "scores = torch.randn( (batch_size, seq_len, num_experts))\n",
    "top_k_scores, top_k_indices = scores.topk(k=2, dim=-1)\n",
    "print(top_k_scores.shape)\n",
    "mask = torch.zeros_like(scores).scatter_(\n",
    "            dim=-1, index=top_k_indices, value=1.0)    \n",
    "print(mask.shape)\n",
    "masked_scores = scores * mask\n",
    "# for 0-> -inf \n",
    "masked_scores = masked_scores.masked_fill(mask == 0, float('-inf'))\n",
    "print(masked_scores)\n",
    "\n",
    "# softmax\n",
    "masked_scores = F.softmax(masked_scores, dim=-1)\n",
    "print(masked_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1, 3])\n",
      "torch.Size([2, 4, 8, 3])\n",
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "num_experts = 3\n",
    "embed_size = 8\n",
    "# (batch_size, seq_len, num_experts)\n",
    "experts_weights= torch.randn( (batch_size, seq_len, num_experts))\n",
    "print(experts_weights.unsqueeze(-2).shape)\n",
    "# 2. get expert_output from experts\n",
    " #[num_experts, (batch_size, seq_len, embed_size)]\n",
    "expert_outputs = [torch.randn( (batch_size, seq_len, embed_size)) for _ in range(num_experts)]\n",
    "# 3. merge expert_output with router_output\n",
    "expert_outputs = torch.stack(expert_outputs,dim=-1) # (batch_size, seq_len, embed_size, num_experts)\n",
    "if torch.isnan(expert_outputs).any():\n",
    "            expert_outputs[\n",
    "                torch.isnan(expert_outputs)\n",
    "            ] = 0\n",
    "print(expert_outputs.shape)\n",
    "# Combine expert outputs and gating scores\n",
    "moe_output = torch.sum(\n",
    "            experts_weights.unsqueeze(-2) * expert_outputs, dim=-1\n",
    "        )\n",
    "print(moe_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fss():\n",
    "    return 1,2\n",
    "\n",
    "fss_list = [fss() for _ in range(3)]\n",
    "out = [x[0] for x in fss_list]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(0, 3, None) slice(3, 5, None)\n",
      "aaa bb\n"
     ]
    }
   ],
   "source": [
    "sta_a = \"aaa\"\n",
    "sta_b = \"bb\"\n",
    "slice1 = slice(0, len(sta_a))\n",
    "slice2 = slice(slice1.stop, len(sta_a) + len(sta_b))\n",
    "print(slice1, slice2)\n",
    "str_ab = sta_a + sta_b\n",
    "print(str_ab[slice1], str_ab[slice2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalle2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
